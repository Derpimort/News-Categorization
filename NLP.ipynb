{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR=\"data/cleaned/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>long_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>ପ୍ରବଳ ଶୀତରେ ଥରୁଛି ସାରା ଓଡ଼ିଶା । ୧୩ଟି ଜିଲ୍ଲା ପାଇ...</td>\n",
       "      <td>https://www.newspointapp.com/odia-news/publish...</td>\n",
       "      <td>କନକ ବ୍ୟୁରୋ : ଜାଡରେ ଥରୁଛି ସାରା ଓଡିଶା । ସ୍ୱାଭାବି...</td>\n",
       "      <td>କନକ ବ୍ୟୁରୋ : ଜାଡରେ ଥରୁଛି ସାରା ଓଡିଶା । ସ୍ୱାଭାବି...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>'संघर्षशील और जुझारू संस्कृतिकर्मी थे संदीपन व...</td>\n",
       "      <td>https://navbharattimes.indiatimes.com/metro/lu...</td>\n",
       "      <td>\\Bसंदीपन ने कलाकारों को दिशा देने के साथ नाट्य...</td>\n",
       "      <td>B Sandipan awakened the play with consciousnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>डीपी रामभरोसे</td>\n",
       "      <td>https://maharashtratimes.indiatimes.com/citize...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>Whipping up nationalism has a shelf life: Kama...</td>\n",
       "      <td>https://www.newspointapp.com/english-news/publ...</td>\n",
       "      <td>BHOPAL: The widespread protests against CAA ar...</td>\n",
       "      <td>BHOPAL: The widespread protests against CAA ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>முலாயம் சிங் மருத்துவமனையில் அனுமதி</td>\n",
       "      <td>https://www.seithisolai.com/mulayam-singh-admi...</td>\n",
       "      <td>சமாஜ்வாதி கட்சியின் நிறுவனத் தலைவர் முலாயம் சி...</td>\n",
       "      <td>Samajwadi Party founder Mulayam Singh has been...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "id                                                        \n",
       "2674  ପ୍ରବଳ ଶୀତରେ ଥରୁଛି ସାରା ଓଡ଼ିଶା । ୧୩ଟି ଜିଲ୍ଲା ପାଇ...   \n",
       "3874  'संघर्षशील और जुझारू संस्कृतिकर्मी थे संदीपन व...   \n",
       "425                                       डीपी रामभरोसे   \n",
       "5177  Whipping up nationalism has a shelf life: Kama...   \n",
       "3260                முலாயம் சிங் மருத்துவமனையில் அனுமதி   \n",
       "\n",
       "                                                   link  \\\n",
       "id                                                        \n",
       "2674  https://www.newspointapp.com/odia-news/publish...   \n",
       "3874  https://navbharattimes.indiatimes.com/metro/lu...   \n",
       "425   https://maharashtratimes.indiatimes.com/citize...   \n",
       "5177  https://www.newspointapp.com/english-news/publ...   \n",
       "3260  https://www.seithisolai.com/mulayam-singh-admi...   \n",
       "\n",
       "                                            description  \\\n",
       "id                                                        \n",
       "2674  କନକ ବ୍ୟୁରୋ : ଜାଡରେ ଥରୁଛି ସାରା ଓଡିଶା । ସ୍ୱାଭାବି...   \n",
       "3874  \\Bसंदीपन ने कलाकारों को दिशा देने के साथ नाट्य...   \n",
       "425                                                 NaN   \n",
       "5177  BHOPAL: The widespread protests against CAA ar...   \n",
       "3260  சமாஜ்வாதி கட்சியின் நிறுவனத் தலைவர் முலாயம் சி...   \n",
       "\n",
       "                                       long_description  \n",
       "id                                                       \n",
       "2674  କନକ ବ୍ୟୁରୋ : ଜାଡରେ ଥରୁଛି ସାରା ଓଡିଶା । ସ୍ୱାଭାବି...  \n",
       "3874  B Sandipan awakened the play with consciousnes...  \n",
       "425                                                 NaN  \n",
       "5177  BHOPAL: The widespread protests against CAA ar...  \n",
       "3260  Samajwadi Party founder Mulayam Singh has been...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# df_langs=pd.read_csv(DATA_DIR+\"langs.csv\")\n",
    "# df_langs=df_langs.set_index('id')\n",
    "df_train=pd.read_pickle(DATA_DIR+\"train_cleaned.pkl\")\n",
    "df_train=df_train.set_index('id')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411103"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 352775, 705550, 1058325, 1411100]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,len(df_train), len(df_train)//4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentences.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darp_lord/Installs/anaconda3/envs/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "100%|██████████| 100/100 [00:04<00:00, 21.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "tagged_sentences=[]\n",
    "selected_phrases=[]\n",
    "proper_nouns=[]\n",
    "\n",
    "cols=['title', 'description', 'long_description']\n",
    "lang_cols=[i+\"_lang\" for i in cols]\n",
    "df_train[cols][df_langs[lang_cols]!='en']=None\n",
    "\n",
    "sentences=df_train['long_description']\n",
    "sentences.fillna(df_train['description'], inplace=True)\n",
    "sentences.fillna(df_train['title'], inplace=True)\n",
    "\n",
    "considered_tags = set(['NN', 'NNS', 'NNP', 'NNPS', 'JJ'])\n",
    "propnoun_tags=set(['NNP', 'NNPS'])\n",
    "\n",
    "def tokenize(sent):\n",
    "    ret_l=[]\n",
    "    for token in nlp(sent):\n",
    "        ret_l.append((token.text, token.tag_,\n",
    "                      #token.lemma_\n",
    "                     ))\n",
    "    return ret_l\n",
    "\n",
    "def extract_phrases(sent):\n",
    "    keyphrase_candidate = set()\n",
    "\n",
    "    np_parser = nltk.RegexpParser(\"\"\"  NP:\n",
    "        {<NN.*|JJ>*<NN.*>}  # Adjective(s)(optional) + Noun(s)\"\"\")  # Noun phrase parser\n",
    "    tree = np_parser.parse(sent)  # Generator with one tree per sentence\n",
    "\n",
    "    for subtree in tree.subtrees(filter=lambda t: t.label() == 'NP'):  # For each nounphrase\n",
    "        # Concatenate the token with a space\n",
    "        keyphrase_candidate.add(' '.join(word for word, tag in subtree.leaves()))\n",
    "\n",
    "    keyphrase_candidate = {kp for kp in keyphrase_candidate if len(kp.split()) <= 5}\n",
    "\n",
    "    keyphrase_candidate = list(keyphrase_candidate)\n",
    "    return keyphrase_candidate\n",
    "\n",
    "def extract_candidates(sent):\n",
    "    ret_l=[]\n",
    "    propnoun_flag=False\n",
    "    propnouns_l=[]\n",
    "    temp=[]\n",
    "    for token in sent:\n",
    "        if token[1] in propnoun_tags:\n",
    "            if propnoun_flag:\n",
    "                temp.append(token[0])\n",
    "            else:\n",
    "                temp=[token[0]]\n",
    "                propnoun_flag=True\n",
    "        elif propnoun_flag:\n",
    "            propnouns_l.append(\" \".join(temp))\n",
    "            propnoun_flag=False\n",
    "        if token[1] in considered_tags and len(token[0])>3:\n",
    "            ret_l.append(token[0])\n",
    "    return np.unique(ret_l), np.unique(propnouns_l)\n",
    "            \n",
    "for sentence in tqdm(sentences):\n",
    "    #\" \".join(simple_preprocess(sentence))\n",
    "    sentence=re.sub(\"[\\\\\\\\\\'\\\"]\", \"\", sentence.lower())\n",
    "    tokenized=tokenize(sentence)\n",
    "    tagged_sentences.append(tokenized)\n",
    "    \n",
    "#     sel_l, pro_l=extract_candidates(tokenized)\n",
    "#     selected_phrases.append(sel_l)\n",
    "#     proper_nouns.append(pro_l)\n",
    "    selected_phrases.append(extract_phrases(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hapur',\n",
       " 'nbt news',\n",
       " 'charge',\n",
       " 'mahavir singh',\n",
       " 'tuesday',\n",
       " 'body',\n",
       " 'forest department',\n",
       " 'national highway-9',\n",
       " 'police station pilkhuwa area',\n",
       " 'inspector',\n",
       " 'reindeer',\n",
       " 'truck',\n",
       " 'station',\n",
       " 'police']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_phrases[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_topk(doc, X, candidates, N=10, beta=0.65, alias_threshold=0.8):\n",
    "    N=min(N, len(candidates))\n",
    "    doc_sim=cosine_similarity(X, doc)\n",
    "    doc_sim_norm = doc_sim/np.max(doc_sim)\n",
    "    doc_sim_norm = 0.5 + (doc_sim_norm - np.average(doc_sim_norm)) / np.std(doc_sim_norm)\n",
    "    sim_between = cosine_similarity(X)\n",
    "    np.fill_diagonal(sim_between, np.NaN)\n",
    "    sim_between_norm = sim_between/np.nanmax(sim_between, axis=0)\n",
    "    sim_between_norm = 0.5 + (sim_between_norm - np.nanmean(sim_between_norm, axis=0)) / np.nanstd(sim_between_norm, axis=0)\n",
    "    selected_candidates = []\n",
    "    unselected_candidates = [c for c in range(len(X))]\n",
    "    j = np.argmax(doc_sim)\n",
    "    selected_candidates.append(j)\n",
    "    unselected_candidates.remove(j)\n",
    "    for _ in range(N-1):\n",
    "        selec_array = np.array(selected_candidates)\n",
    "        unselec_array = np.array(unselected_candidates)\n",
    "        distance_to_doc = doc_sim_norm[unselec_array, :]\n",
    "        dist_between = sim_between_norm[unselec_array][:, selec_array]\n",
    "        if dist_between.ndim == 1:\n",
    "            dist_between = dist_between[:, np.newaxis]\n",
    "        j = np.argmax(beta * distance_to_doc - (1 - beta) * np.max(dist_between, axis=1).reshape(-1, 1))\n",
    "        item_idx = unselected_candidates[j]\n",
    "        selected_candidates.append(item_idx)\n",
    "        unselected_candidates.remove(item_idx)\n",
    "    return candidates[selected_candidates].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
